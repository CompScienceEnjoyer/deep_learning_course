{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#train"
      ],
      "metadata": {
        "id": "Vb6fU4c9cDfv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVEVloLUbJU2"
      },
      "outputs": [],
      "source": [
        "for k in range(20):\n",
        "\n",
        "    # forward\n",
        "    total_loss = 0\n",
        "    acc = 0\n",
        "    for i in range(len(xs)):\n",
        "        x = torch.tensor(xs[i], dtype=torch.float32)\n",
        "        y = torch.tensor([ys[i]], dtype=torch.float32)\n",
        "        output = n.forward(x)\n",
        "        total_loss += (output - y) ** 2\n",
        "        acc += 0.01\n",
        "\n",
        "    # calculate loss (mean square error)\n",
        "    total_loss /= len(xs)\n",
        "\n",
        "    # backward (zero_grad + backward)\n",
        "    n.zero_grad()\n",
        "    total_loss.backward()\n",
        "\n",
        "    # update\n",
        "    learning_rate = 0.1\n",
        "    for p in n.parameters():\n",
        "        p.data -= learning_rate * p.grad.data\n",
        "\n",
        "    if k % 1 == 0:\n",
        "        print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")"
      ]
    }
  ]
}