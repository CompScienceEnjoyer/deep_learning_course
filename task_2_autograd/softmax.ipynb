{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Softmax\n",
        "не выполнил. загрузил, чтобы доделать в дальнейшем"
      ],
      "metadata": {
        "id": "VU8WhE_Nyx1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_tensor_params(*tensors):\n",
        "  for x in tensors:\n",
        "    print('---')\n",
        "    print(f\"data - {x.data}\")\n",
        "    print(f\"grad - {x.grad}\")\n",
        "    print(f\"grad_fn - {x.grad_fn}\")\n",
        "    print(f\"req_grad - {x.requires_grad}\")\n",
        "    print(f\"is_leaf - {x.is_leaf}\")"
      ],
      "metadata": {
        "id": "SVV76kp33HOK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Blsdiw4nyqTj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "class _softmax(torch.autograd.Function):\n",
        "\n",
        "    def forward(ctx, x):\n",
        "        exp_x = []\n",
        "        for i in range(len(x)):\n",
        "            exp_x.append(math.exp(x[i]))\n",
        "        x_prob = []\n",
        "        for i in range(len(x)):\n",
        "            x_prob.append(exp_x[i]/sum(exp_x))\n",
        "        ctx.save_for_backward(x_prob)\n",
        "        return x_prob\n",
        "\n",
        "    def backward(ctx, out_grad):\n",
        "        xs = ctx.saved_tensors\n",
        "        in_grad = xs * (out_grad - torch.sum(xs*out_grad, dim = 1, keepdim = True))\n",
        "        return in_grad\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import I\n",
        "input = torch.tensor([2.1, 2.0, 2.0, 8.8], requires_grad=True)\n",
        "sm = torch.nn.Softmax(dim=0)\n",
        "output = sm(input)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Nd3DMj2xey",
        "outputId": "88612553-0952-4022-d580-ae73190ca17c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0012, 0.0011, 0.0011, 0.9966], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.sum().backward()\n",
        "show_tensor_params(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DORszbB24t4",
        "outputId": "0f2feb87-d5b5-4288-ca5d-19280c9b0d20"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "data - tensor([2.1000, 2.0000, 2.0000, 8.8000])\n",
            "grad - tensor([7.3115e-11, 6.6157e-11, 6.6157e-11, 5.9399e-08])\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_softmax = _softmax.apply(input)\n",
        "print(my_softmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "Z1L5wGcK4CuD",
        "outputId": "bc71cbb7-c8e3-4d5b-b507-0dc63a9d33da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-346da55718ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_softmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_softmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_context\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_SingleLevelFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: save_for_backward can only save variables, but argument 0 is of type list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.tensor([2.1, 2.0, 2.0, 8.8], requires_grad=True)\n",
        "sm = torch.nn.Softmax(dim=0)\n",
        "output = sm(input)\n",
        "ground_true = torch.tensor([0., 0., 0., 1.])\n",
        "\n",
        "\n",
        "loss = (output - ground_true) ** 2\n",
        "loss = loss.sum().backward()\n",
        "show_tensor_params(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4ZNBxit260N",
        "outputId": "a4381762-0feb-4cb5-8524-2a3c05a9aade"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "data - tensor([2.1000, 2.0000, 2.0000, 8.8000])\n",
            "grad - tensor([ 1.1426e-05,  1.0080e-05,  1.0080e-05, -3.1586e-05])\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.tensor([2.1, 2.0, 2.0, 8.8], requires_grad=True)\n",
        "sm = torch.nn.Softmax(dim=0)\n",
        "output = sm(input)\n",
        "ground_true = torch.tensor([1., 1., 0., 1.])\n",
        "\n",
        "\n",
        "loss = (output - ground_true) ** 2\n",
        "loss = loss.sum().backward()\n",
        "show_tensor_params(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6-ROrIk3ZTK",
        "outputId": "92585913-b833-4f74-ee57-2517d8bd7f8b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "data - tensor([2.1000, 2.0000, 2.0000, 8.8000])\n",
            "grad - tensor([-2.4362e-03, -2.2046e-03,  1.5267e-05,  4.6255e-03])\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Qlf4LKa3gL7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}